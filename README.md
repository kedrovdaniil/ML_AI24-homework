# ML_AI24-homework

## Домашнее задание 1

1. **Предобработка данных.** Мы начали с анализа набора данных:
   Проверили качество данных - выявили пропуски и дубликаты.
   Построили отчёт по датасету с помощью библиотеки ydata-profiling.
   Заполнили пропуски медианными значениями, рассчитанными на основе тренировочного набора.
   Преобразовали числовые признаки, содержащие текст (`mileage`, `engine`, `max_power`), в числовой формат.
   Удалили признак `torque`.

2. **Построение базовой модели.**
   Обучили линейную регрессию на вещественных признаках для прогнозирования цены подержанных автомобилей.
   Метрики качества модели:

- $R^2$ на тестовых данных: 0.5941
- $R^2$ на тренировочных данных: 0.5923
- MSE на тестовых данных: 233297548204.61
- MSE на тренировочных данных: 116873067751.52\
  _Модель показала средние результаты без признаков переобучения._

3. **Стандартизация признаков.**
   Мы предположили, что стандартизация (с использованием `StandardScaler`) может улучшить качество модели. Однако значения метрик остались неизменными, так как линейная регрессия компенсировала масштабирование пересчётом коэффициентов.
   Стандартизация позволила интерпретировать важность признаков, наиболее значимым оказался `max_power` (максимальная мощность двигателя), а наименее значимым — `seats` (количество мест).

4. **Регуляризация и подбор параметров.**
   Для улучшения модели мы применили регуляризацию:\
   _Lasso-регрессия:_ метрики качества не изменились. Все признаки остались значимыми, коэффициенты не занулились.\
   _Метрики Lasso:_

- Оптимальные параметры: `alpha=100`\
- $R^2$ на тренировочных данных: 0.5722
  _ElasticNet-регрессия:_ с использованием кросс-валидации мы подобрали оптимальные параметры: `alpha=1`, `l1_ratio=0.9`.\
  _Метрики ElasticNet:_
- $R^2$ на тестовых данных: 0.5682
- MSE на тестовых данных: 245892672007.80

5. **Добавление категориальных признаков.**
   Закодировали категориальные признаки (`fuel`, `seller_type`, `transmission`, `owner`) и `seats` методом OneHot-кодирования с устранением мультиколлинеарности.
   Обучили Ridge-регрессию, подобрав параметр `alpha` с помощью кросс-валидации (10 фолдов).
   Качество модели незначительно улучшилось:

- Лучший alpha: {'alpha': 100}
- $R^2$ на тестовых данных: 0.6034

6. **Бизнес-метрика**
   Мы реализовали кастомную метрику, оценивающую долю прогнозов, отклоняющихся от реальных значений не более чем на 10%. Результаты:

- Linear Regression (без стандартизации): 22.7%.
- Linear Regression (с стандартизацией): 22.7%.
- Lasso (регуляризация): 22.7%.
- ElasticNet (регуляризация и кросс-валидация): 24.1%.

# Итог

Модель ElasticNet оказалась самой точной для бизнес-метрики — она дала 24.1% прогнозов с ошибкой не больше 10%. Это немного лучше, чем у остальных моделей.

Результаты первых трёх моделей почти не отличаются, потому что:

1. В данных, скорее всего, уже есть хорошие связи, которые линейная регрессия смогла уловить.
2. Регуляризация (например, в Lasso) почти не изменила модель, так как признаки и так достаточно важны.

**Почему ElasticNet работает лучше?**  
ElasticNet сочетает два метода регуляризации, поэтому она могла немного точнее подобрать веса: убрать менее важные признаки и чуть лучше настроиться на данные.

Для этой задачи я бы посоветовал использовать ElasticNet, а если нужно улучшить точность, можно попробовать более сложные модели.
